{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import traceback\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Lambda, LeakyReLU, AveragePooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import hist\n",
    "from PIL import Image\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH, IMAGE_HEIGHT = 227, 227\n",
    "random.seed(52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(input_data, output_data, batch_size, is_training):\n",
    "    input_data_batch = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
    "    output_data_batch = np.empty([batch_size, 1])\n",
    "    while True:\n",
    "        index = 0\n",
    "        for i in np.random.permutation(input_data.shape[0]):\n",
    "            input_data_batch[index] = input_data[i]\n",
    "            output_data_batch[index] = output_data[i]\n",
    "            index += 1\n",
    "            if index == batch_size:\n",
    "                break\n",
    "        yield input_data_batch, output_data_batch\n",
    "\n",
    "\n",
    "def _preprocess(image_loc: str) -> np.ndarray:\n",
    "    f_image = Image.open(image_loc).convert('L')\n",
    "    f_image = f_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.ANTIALIAS)\n",
    "    image = np.asarray(f_image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = np.expand_dims(image, axis=3)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess(loc: str) -> np.ndarray:\n",
    "    \"\"\"Safety wrapper over _preprocess.\n",
    "    \n",
    "    Args:\n",
    "        loc: File location to check if dir or an image.\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed image(s) as an ndarray.\n",
    "    \"\"\"\n",
    "    if os.path.isdir(loc):\n",
    "        current = np.concatenate((\n",
    "            [_preprocess(os.path.join(loc, image)) for image in os.listdir(loc)\n",
    "             if '.png' in image]\n",
    "        ))\n",
    "    else:\n",
    "        current = _preprocess(loc)\n",
    "    return current\n",
    "\n",
    "\n",
    "def generate_data_arrays(\n",
    "    covid_data: str = 'rsc/New_Data_CoV2/COVID/',\n",
    "    noncovid_data: str = 'rsc/New_Data_CoV2/non-COVID/',\n",
    "    others_data:  str = 'rsc/New_Data_CoV2/Others/',\n",
    "    image_output: str = 'rsc/input_data_v2',\n",
    "    label_output: str = 'rsc/output_data_v2',\n",
    "    regenerate: bool = True\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads COVID images into ndarrays.\n",
    "    \n",
    "    Args:\n",
    "        covid_data: Relative path to folder containing COVID images.\n",
    "        noncovid_data: Relative path to folder containing non-COVID images.\n",
    "        others_data: Relative path to folder containing Others images.\n",
    "        image_output: Relative path (with filename) to save loaded images to.\n",
    "        label_output: Relative path (with filename) to save loaded classes (labels) to.\n",
    "        regenerate: If True, will regenerate saved ndarray files for both image_output\n",
    "            and label_output, even if they already exist (overwriting them). If False,\n",
    "            will simply load and return the aforementioned.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of ndarrays. The first is the loaded image data in one large ndarray,\n",
    "        and the second is the loaded labels, also in a large ndarray. These directly\n",
    "        match up to each other ONLY when both arrays (and their respective files)\n",
    "        are generated at the same time with this method.\n",
    "    \"\"\"\n",
    "    if (regenerate is False and \n",
    "        os.path.isfile(f'{out_input_data}.npy') and\n",
    "        os.path.isfile(f'{out_output_data}.npy')):\n",
    "        return (np.load(f'{out_input_data}.npy'),\n",
    "                np.load(f'{out_output_data}.npy'))\n",
    "    \n",
    "    if not ((cd := os.path.exists(covid_data)) and (ncd := os.path.exists(noncovid_data))):\n",
    "        if (others_data is not None) and not (odd := os.path.exists(others_data)):\n",
    "            raise NotADirectoryError(\"Directories do not exist.\")\n",
    "        else:\n",
    "            raise NotADirectoryError(\"COVID/non-COVID directories do not exist.\")\n",
    "    \n",
    "    im_data = np.empty([1, IMAGE_WIDTH, IMAGE_WIDTH, 1])\n",
    "    output = np.array([0])\n",
    "\n",
    "    print('Loading Covid Data')\n",
    "    for i in tqdm(glob.glob(os.path.join(covid_data, '**'))):\n",
    "        current = preprocess(i)\n",
    "        im_data = np.concatenate((im_data, current))\n",
    "        output = np.concatenate((output, np.array([1])), axis=0)\n",
    "\n",
    "    print('Loading non-Covid Data')\n",
    "    for i in tqdm(glob.glob(os.path.join(noncovid_data, '**'))):\n",
    "        current = preprocess(i)\n",
    "        im_data = np.concatenate((im_data, current))\n",
    "        output = np.concatenate((output, np.array([0])), axis=0)\n",
    "        \n",
    "    if others_data is not None:\n",
    "        print('Loading Others Data')\n",
    "        for i in tqdm(glob.glob(os.path.join(others_data, '**'))):\n",
    "            current = preprocess(i)\n",
    "            im_data = np.concatenate((im_data, current))\n",
    "            output = np.concatenate((output, np.array([-1])), axis=0)\n",
    "    else:\n",
    "        print('Others data not provided; skipping.')\n",
    "\n",
    "\n",
    "    print('Finished Loading Data')\n",
    "    im_data = np.delete(im_data, 0, axis=0)\n",
    "    output = np.delete(output, 0, axis=0)\n",
    "\n",
    "    zip_data = list(zip(im_data, output))\n",
    "    random.shuffle(zip_data)\n",
    "    im_data, output = zip(*zip_data)\n",
    "\n",
    "    np.save(f'{image_output}', im_data)\n",
    "    np.save(f'{label_output}', output)\n",
    "    return im_data, output\n",
    "\n",
    "\n",
    "def load_data(image_loc: str, label_loc: str, **kwargs) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Attempts to load generated images and labels.\n",
    "    \n",
    "    If either is not found, attempts to (re)generate them using the default\n",
    "    input arguments to the generation method for the raw data, but the input\n",
    "    `image_loc` and `label_loc` parameters for the output arrays. If this\n",
    "    still does not work, returns a general error and exits.\n",
    "    \n",
    "    Args:\n",
    "        image_loc: Relative path to saved image ndarray file.\n",
    "        label_loc: Relative path to saved label ndarray file.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of ndarrays. The first array holds the loaded image data, whilst\n",
    "        the second array holds their respective labels.\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_data = np.load(f'{image_loc}.npy')\n",
    "        label_data = np.load(f'{label_loc}.npy')\n",
    "        return image_data, label_data\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            image_data, label_data = generate_data_arrays(\n",
    "                image_output = image_loc,\n",
    "                label_output = label_loc,\n",
    "                **kwargs\n",
    "            )\n",
    "            return image_data, label_data\n",
    "        \n",
    "        except Exception as e:\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 1\n",
    "im_data_v3, output_v3 = load_data(\n",
    "    image_loc = 'rsc/input_data_v3',\n",
    "    label_loc = 'rsc/output_data_v3',\n",
    "    covid_data = 'rsc/New_Data_CoV2/Non-Healthy/',\n",
    "    noncovid_data = 'rsc/New_Data_CoV2/Healthy/',\n",
    "    others_data = None,\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(im_data_v3, output_v3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(X_Train, Y_Train, X_Test, Y_Test, model_dir: str):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    #X_Train, X_Test, Y_Train, Y_Test = train_test_split(input_data, output_data, test_size=0.1)\n",
    "\n",
    "    for_pad = lambda s: s if s > 2 else 3\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1)))\n",
    "\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=8, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=16, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=32, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(1) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(1, 1), filters=16, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=32, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=64, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(1) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(1, 1), filters=32, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=64, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=128, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(1) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(1, 1), filters=64, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=128, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=256, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(1) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(1, 1), filters=128, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(3) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=256, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(1) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(1, 1), filters=128, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "\n",
    "    #model.add(ZeroPadding2D(padding=(for_pad(19) - 1)//2))\n",
    "    model.add(Conv2D(kernel_size=(3, 3), filters=256, strides=(1, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    #model.add(Conv2D(kernel_size=(3, 3), filters=2, strides=(1, 1),activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dropout(rate=0.4))\n",
    "    model.add(Dense(units=338, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=3e-4), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    checkpoint = ModelCheckpoint(os.path.join(model_dir, 'xRGM3.2'), verbose=1, period=1, save_best_only=True)\n",
    "\n",
    "    hist = model.fit_generator(batch_generator(X_Train, Y_Train, 128, True),\n",
    "                        validation_data=(batch_generator(X_Test, Y_Test, 128, False)), callbacks=[checkpoint],\n",
    "                        verbose=1, epochs=75, steps_per_epoch=25, validation_steps=len(X_Test))\n",
    "\n",
    "    with open(os.path.join('models', 'xRGM3.2-Net-HistDict'), 'wb') as f:\n",
    "        pickle.dump(hist.history, f)\n",
    "\n",
    "    model.save(model_dir)\n",
    "    \n",
    "    return model\n",
    "#healthy vs non-healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 227, 227, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 225, 225, 8)       80        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 225, 225, 8)       32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 225, 225, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 110, 110, 16)      1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 110, 110, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 110, 110, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 108, 108, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 108, 108, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 108, 108, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 108, 108, 16)      528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 108, 108, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 108, 108, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 106, 106, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 106, 106, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 106, 106, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 104, 104, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 104, 104, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 104, 104, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 104, 104, 32)      2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 104, 104, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 102, 102, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 102, 102, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 102, 102, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100, 100, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 100, 100, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 100, 100, 64)      8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100, 100, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 98, 98, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 98, 98, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 98, 98, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 47, 47, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 47, 47, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 47, 47, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 47, 47, 128)       32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 47, 47, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 47, 47, 128)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 21, 21, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 21, 21, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 21, 21, 256)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 10, 10, 128)       32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 338)               5538130   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 339       \n",
      "=================================================================\n",
      "Total params: 6,702,293\n",
      "Trainable params: 6,699,077\n",
      "Non-trainable params: 3,216\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jg1994/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "25/25 [==============================] - 1688s 68s/step - loss: 1.2296 - accuracy: 0.7468 - val_loss: 1.2017 - val_accuracy: 0.3828\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.20173, saving model to model/xRGM3.2/xRGM3.2\n",
      "INFO:tensorflow:Assets written to: model/xRGM3.2/xRGM3.2/assets\n",
      "Epoch 2/75\n",
      "25/25 [==============================] - 1674s 68s/step - loss: 0.0327 - accuracy: 0.9974 - val_loss: 1.9821 - val_accuracy: 0.3828\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.20173\n",
      "Epoch 3/75\n",
      "25/25 [==============================] - 1401s 56s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.3500 - val_accuracy: 0.3828\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.20173\n",
      "Epoch 4/75\n",
      "25/25 [==============================] - 1652s 67s/step - loss: 4.0886e-04 - accuracy: 1.0000 - val_loss: 5.5514 - val_accuracy: 0.3828\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.20173\n",
      "Epoch 5/75\n",
      "25/25 [==============================] - 1652s 67s/step - loss: 2.7695e-04 - accuracy: 1.0000 - val_loss: 9.2557 - val_accuracy: 0.4141\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.20173\n",
      "Epoch 6/75\n",
      "25/25 [==============================] - 1557s 63s/step - loss: 2.1042e-04 - accuracy: 1.0000 - val_loss: 15.4511 - val_accuracy: 0.4062\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.20173\n",
      "Epoch 7/75\n",
      "25/25 [==============================] - 1474s 60s/step - loss: 1.7448e-04 - accuracy: 1.0000 - val_loss: 24.4916 - val_accuracy: 0.4219\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.20173\n",
      "Epoch 8/75\n",
      "25/25 [==============================] - 1649s 67s/step - loss: 1.4131e-04 - accuracy: 1.0000 - val_loss: 36.8782 - val_accuracy: 0.4297\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.20173\n",
      "Epoch 9/75\n",
      "25/25 [==============================] - 1647s 66s/step - loss: 1.1657e-04 - accuracy: 1.0000 - val_loss: 52.9150 - val_accuracy: 0.4375\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.20173\n",
      "Epoch 10/75\n",
      "25/25 [==============================] - 1418s 57s/step - loss: 1.0109e-04 - accuracy: 1.0000 - val_loss: 72.3953 - val_accuracy: 0.4453\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.20173\n",
      "Epoch 11/75\n",
      "25/25 [==============================] - 1596s 65s/step - loss: 8.6355e-05 - accuracy: 1.0000 - val_loss: 93.9363 - val_accuracy: 0.4688\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.20173\n",
      "Epoch 12/75\n",
      "25/25 [==============================] - 1642s 66s/step - loss: 7.5564e-05 - accuracy: 1.0000 - val_loss: 117.9448 - val_accuracy: 0.4688\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.20173\n",
      "Epoch 13/75\n",
      "25/25 [==============================] - 1648s 67s/step - loss: 6.6751e-05 - accuracy: 1.0000 - val_loss: 141.1811 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.20173\n",
      "Epoch 14/75\n",
      "25/25 [==============================] - 1416s 57s/step - loss: 5.8954e-05 - accuracy: 1.0000 - val_loss: 163.3336 - val_accuracy: 0.5078\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.20173\n",
      "Epoch 15/75\n",
      "25/25 [==============================] - 1649s 67s/step - loss: 5.3069e-05 - accuracy: 1.0000 - val_loss: 183.9050 - val_accuracy: 0.5156\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.20173\n",
      "Epoch 16/75\n",
      "25/25 [==============================] - 1647s 66s/step - loss: 4.7832e-05 - accuracy: 1.0000 - val_loss: 203.3498 - val_accuracy: 0.5312\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.20173\n",
      "Epoch 17/75\n",
      "25/25 [==============================] - 1499s 60s/step - loss: 4.1018e-05 - accuracy: 1.0000 - val_loss: 220.7637 - val_accuracy: 0.5391\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.20173\n",
      "Epoch 18/75\n",
      "25/25 [==============================] - 1515s 61s/step - loss: 3.5609e-05 - accuracy: 1.0000 - val_loss: 234.8792 - val_accuracy: 0.5391\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.20173\n",
      "Epoch 19/75\n",
      "25/25 [==============================] - 1642s 66s/step - loss: 3.4929e-05 - accuracy: 1.0000 - val_loss: 246.0140 - val_accuracy: 0.5469\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.20173\n",
      "Epoch 20/75\n",
      "25/25 [==============================] - 1651s 67s/step - loss: 3.2839e-05 - accuracy: 1.0000 - val_loss: 256.0066 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.20173\n",
      "Epoch 21/75\n",
      "25/25 [==============================] - 1373s 55s/step - loss: 2.9981e-05 - accuracy: 1.0000 - val_loss: 264.3977 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.20173\n",
      "Epoch 22/75\n",
      "25/25 [==============================] - 1637s 66s/step - loss: 2.6648e-05 - accuracy: 1.0000 - val_loss: 271.5263 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.20173\n",
      "Epoch 23/75\n",
      "25/25 [==============================] - 1658s 67s/step - loss: 2.5726e-05 - accuracy: 1.0000 - val_loss: 276.8701 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.20173\n",
      "Epoch 24/75\n",
      "25/25 [==============================] - 1592s 64s/step - loss: 2.3947e-05 - accuracy: 1.0000 - val_loss: 282.0303 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.20173\n",
      "Epoch 25/75\n",
      "25/25 [==============================] - 1446s 58s/step - loss: 2.1970e-05 - accuracy: 1.0000 - val_loss: 285.1484 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.20173\n",
      "Epoch 26/75\n",
      "25/25 [==============================] - 1650s 67s/step - loss: 2.1642e-05 - accuracy: 1.0000 - val_loss: 287.4914 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.20173\n",
      "Epoch 27/75\n",
      "25/25 [==============================] - 1654s 67s/step - loss: 1.7434e-05 - accuracy: 1.0000 - val_loss: 290.2304 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.20173\n",
      "Epoch 28/75\n",
      "25/25 [==============================] - 1450s 58s/step - loss: 1.7795e-05 - accuracy: 1.0000 - val_loss: 293.0341 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.20173\n",
      "Epoch 29/75\n",
      "25/25 [==============================] - 1574s 64s/step - loss: 1.7689e-05 - accuracy: 1.0000 - val_loss: 294.3712 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.20173\n",
      "Epoch 30/75\n",
      "25/25 [==============================] - 1651s 67s/step - loss: 1.5481e-05 - accuracy: 1.0000 - val_loss: 295.6218 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.20173\n",
      "Epoch 31/75\n",
      "25/25 [==============================] - 1646s 66s/step - loss: 1.5676e-05 - accuracy: 1.0000 - val_loss: 295.9297 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.20173\n",
      "Epoch 32/75\n",
      "25/25 [==============================] - 1391s 56s/step - loss: 1.4253e-05 - accuracy: 1.0000 - val_loss: 297.3313 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.20173\n",
      "Epoch 33/75\n",
      "25/25 [==============================] - 1651s 67s/step - loss: 1.2397e-05 - accuracy: 1.0000 - val_loss: 298.8923 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.20173\n",
      "Epoch 34/75\n",
      "25/25 [==============================] - 1647s 66s/step - loss: 1.3019e-05 - accuracy: 1.0000 - val_loss: 298.4463 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.20173\n",
      "Epoch 35/75\n",
      "25/25 [==============================] - 1514s 61s/step - loss: 1.1292e-05 - accuracy: 1.0000 - val_loss: 299.9241 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.20173\n",
      "Epoch 36/75\n",
      "25/25 [==============================] - 1490s 60s/step - loss: 1.2275e-05 - accuracy: 1.0000 - val_loss: 300.4094 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.20173\n",
      "Epoch 37/75\n",
      "25/25 [==============================] - 1646s 66s/step - loss: 1.1523e-05 - accuracy: 1.0000 - val_loss: 300.4592 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.20173\n",
      "Epoch 38/75\n",
      "25/25 [==============================] - 1651s 67s/step - loss: 1.0184e-05 - accuracy: 1.0000 - val_loss: 300.5500 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.20173\n",
      "Epoch 39/75\n",
      "25/25 [==============================] - 1392s 56s/step - loss: 9.5276e-06 - accuracy: 1.0000 - val_loss: 301.1631 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.20173\n",
      "Epoch 40/75\n",
      "25/25 [==============================] - 1619s 66s/step - loss: 9.3025e-06 - accuracy: 1.0000 - val_loss: 302.0847 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.20173\n",
      "Epoch 41/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1652s 67s/step - loss: 9.0772e-06 - accuracy: 1.0000 - val_loss: 302.3535 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.20173\n",
      "Epoch 42/75\n",
      "25/25 [==============================] - 1628s 66s/step - loss: 8.1435e-06 - accuracy: 1.0000 - val_loss: 302.2581 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.20173\n",
      "Epoch 43/75\n",
      "25/25 [==============================] - 1417s 57s/step - loss: 7.9363e-06 - accuracy: 1.0000 - val_loss: 302.2402 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.20173\n",
      "Epoch 44/75\n",
      "25/25 [==============================] - 1647s 66s/step - loss: 7.3968e-06 - accuracy: 1.0000 - val_loss: 302.2400 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.20173\n",
      "Epoch 45/75\n",
      "25/25 [==============================] - 1646s 66s/step - loss: 7.4982e-06 - accuracy: 1.0000 - val_loss: 302.5286 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.20173\n",
      "Epoch 46/75\n",
      "25/25 [==============================] - 1469s 59s/step - loss: 7.2602e-06 - accuracy: 1.0000 - val_loss: 303.8271 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.20173\n",
      "Epoch 47/75\n",
      "25/25 [==============================] - 1550s 63s/step - loss: 7.0655e-06 - accuracy: 1.0000 - val_loss: 304.0271 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.20173\n",
      "Epoch 48/75\n",
      "25/25 [==============================] - 1647s 66s/step - loss: 6.5970e-06 - accuracy: 1.0000 - val_loss: 303.2421 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.20173\n",
      "Epoch 49/75\n",
      "25/25 [==============================] - 1650s 67s/step - loss: 6.3916e-06 - accuracy: 1.0000 - val_loss: 303.4143 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.20173\n",
      "Epoch 50/75\n",
      "25/25 [==============================] - 1358s 54s/step - loss: 5.8679e-06 - accuracy: 1.0000 - val_loss: 303.3962 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.20173\n",
      "Epoch 51/75\n",
      "25/25 [==============================] - 1638s 66s/step - loss: 5.8877e-06 - accuracy: 1.0000 - val_loss: 303.5147 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.20173\n",
      "Epoch 52/75\n",
      "25/25 [==============================] - 1643s 66s/step - loss: 6.0060e-06 - accuracy: 1.0000 - val_loss: 303.6153 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.20173\n",
      "Epoch 53/75\n",
      "25/25 [==============================] - 1565s 63s/step - loss: 7.0785e-06 - accuracy: 1.0000 - val_loss: 303.0759 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.20173\n",
      "Epoch 54/75\n",
      "25/25 [==============================] - 1455s 59s/step - loss: 5.4645e-06 - accuracy: 1.0000 - val_loss: 303.3124 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.20173\n",
      "Epoch 55/75\n",
      "25/25 [==============================] - 1657s 67s/step - loss: 5.4988e-06 - accuracy: 1.0000 - val_loss: 304.4200 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.20173\n",
      "Epoch 56/75\n",
      "25/25 [==============================] - 1649s 67s/step - loss: 5.7236e-06 - accuracy: 1.0000 - val_loss: 304.7520 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.20173\n",
      "Epoch 57/75\n",
      "25/25 [==============================] - 1440s 58s/step - loss: 5.1556e-06 - accuracy: 1.0000 - val_loss: 305.0577 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.20173\n",
      "Epoch 58/75\n",
      "25/25 [==============================] - 1583s 64s/step - loss: 4.8955e-06 - accuracy: 1.0000 - val_loss: 305.0926 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.20173\n",
      "Epoch 59/75\n",
      "25/25 [==============================] - 1649s 67s/step - loss: 4.4680e-06 - accuracy: 1.0000 - val_loss: 305.2620 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.20173\n",
      "Epoch 60/75\n",
      "25/25 [==============================] - 1653s 67s/step - loss: 3.9675e-06 - accuracy: 1.0000 - val_loss: 305.2900 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.20173\n",
      "Epoch 61/75\n",
      "25/25 [==============================] - 1376s 55s/step - loss: 4.4373e-06 - accuracy: 1.0000 - val_loss: 305.0916 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.20173\n",
      "Epoch 62/75\n",
      "25/25 [==============================] - 1646s 66s/step - loss: 4.2458e-06 - accuracy: 1.0000 - val_loss: 304.6689 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.20173\n",
      "Epoch 63/75\n",
      "25/25 [==============================] - 1651s 67s/step - loss: 3.8706e-06 - accuracy: 1.0000 - val_loss: 305.0505 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.20173\n",
      "Epoch 64/75\n",
      "25/25 [==============================] - 1514s 61s/step - loss: 3.8367e-06 - accuracy: 1.0000 - val_loss: 305.0154 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.20173\n",
      "Epoch 65/75\n",
      "25/25 [==============================] - 1495s 60s/step - loss: 4.2164e-06 - accuracy: 1.0000 - val_loss: 304.3945 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.20173\n",
      "Epoch 66/75\n",
      "25/25 [==============================] - 1427s 57s/step - loss: 3.7902e-06 - accuracy: 1.0000 - val_loss: 303.9783 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.20173\n",
      "Epoch 67/75\n",
      "25/25 [==============================] - 1355s 55s/step - loss: 3.3758e-06 - accuracy: 1.0000 - val_loss: 304.4590 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.20173\n",
      "Epoch 68/75\n",
      "25/25 [==============================] - 1060s 43s/step - loss: 3.3086e-06 - accuracy: 1.0000 - val_loss: 305.0214 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.20173\n",
      "Epoch 69/75\n",
      "25/25 [==============================] - 1341s 54s/step - loss: 3.2590e-06 - accuracy: 1.0000 - val_loss: 305.3342 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.20173\n",
      "Epoch 70/75\n",
      "25/25 [==============================] - 1363s 55s/step - loss: 3.1028e-06 - accuracy: 1.0000 - val_loss: 305.7225 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.20173\n",
      "Epoch 71/75\n",
      "25/25 [==============================] - 1500s 61s/step - loss: 2.9586e-06 - accuracy: 1.0000 - val_loss: 305.8125 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.20173\n",
      "Epoch 72/75\n",
      "25/25 [==============================] - 1482s 60s/step - loss: 3.2685e-06 - accuracy: 1.0000 - val_loss: 306.0273 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.20173\n",
      "Epoch 73/75\n",
      "25/25 [==============================] - 1656s 67s/step - loss: 2.8142e-06 - accuracy: 1.0000 - val_loss: 305.7908 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.20173\n",
      "Epoch 74/75\n",
      "25/25 [==============================] - 1651s 67s/step - loss: 2.8320e-06 - accuracy: 1.0000 - val_loss: 305.4697 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.20173\n",
      "Epoch 75/75\n",
      "25/25 [==============================] - 1431s 57s/step - loss: 2.9319e-06 - accuracy: 1.0000 - val_loss: 305.0803 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.20173\n",
      "INFO:tensorflow:Assets written to: model/xRGM3.2/assets\n",
      "CPU times: user 4d 14h 10min 42s, sys: 3h 4min 38s, total: 4d 17h 15min 21s\n",
      "Wall time: 1d 8h 24min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dir: str = 'model/xRGM3.2'\n",
    "xRGM = make_model(x_train, y_train.reshape(-1,1), x_test, y_test.reshape(-1,1), model_dir=model_dir)\n",
    "\n",
    "v_classify = np.vectorize(lambda x: np.round(x, 0))\n",
    "# xRGMCT2 = load_model('models/xRGMCT2L.h5')\n",
    "# print(xRGMCT2.history)\n",
    "y_pred = (xRGM.predict(x_test))\n",
    "\n",
    "#print(y_test)\n",
    "#print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:    0.8867924528301887\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.5384615384615384\n",
      "F1 Score:    0.7000000000000001\n",
      "\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                   7                   6\n",
      "Actual Positive                   0                  40\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, v_classify(y_pred)),\n",
    "                                columns=['Predicted Negative', 'Predicted Positive'],\n",
    "                                index=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "tp, tn, fp, fn = (\n",
    "    confusion_matrix.iloc[1,1], \n",
    "    confusion_matrix.iloc[0,0], \n",
    "    confusion_matrix.iloc[0,1], \n",
    "    confusion_matrix.iloc[1,0]\n",
    ")\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1_score = 2 * ((specificity * sensitivity) / (specificity + sensitivity))\n",
    "\n",
    "with open(os.path.join(f'{model_dir}', 'metrics.csv'), 'a', encoding='utf-8') as f:\n",
    "    f.write(\n",
    "        f'{time.strftime(\"%Y-%m-%dT%H:%M:%S-05:00\", time.localtime())}, {accuracy}, {sensitivity}, {specificity}, {f1_score}\\n'\n",
    "    )\n",
    "\n",
    "print(f'Accuracy:    {accuracy}')\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'F1 Score:    {f1_score}')\n",
    "print('\\n')\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 227, 227, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disease_types=['Non-Healthy', 'Healthy']\n",
    "Y_pred = np.argmax(y_pred)\n",
    "Y_true = np.argmax(y_test)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "ax = sns.heatmap(confusion_matrix , cmap=plt.cm.GnBu , \n",
    "                 annot=True, fmt='d',square=True, xticklabels=disease_types, \n",
    "                 yticklabels=disease_types)\n",
    "ax.set_ylabel('Actual', fontsize=20)\n",
    "ax.set_xlabel('Predicted', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "   fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "   # summarize history for accuracy\n",
    "   axs[0].plot(range(1, len(model_history['accuracy']) + 1), model_history['accuracy'])\n",
    "   axs[0].plot(range(1, len(model_history['val_accuracy']) + 1), model_history['val_accuracy'])\n",
    "   axs[0].set_title('Model Accuracy')\n",
    "   axs[0].set_ylabel('Accuracy')\n",
    "   axs[0].set_xlabel('Epoch')\n",
    "   axs[0].set_xticks(np.arange(1, len(model_history['accuracy']) + 1), len(model_history['accuracy']) / 10)\n",
    "   axs[0].legend(['train', 'val'], loc='best')\n",
    "   # summarize history for loss\n",
    "   axs[1].plot(range(1, len(model_history['loss'])+1), model_history['loss'])\n",
    "   axs[1].plot(range(1, len(model_history['val_loss']) + 1), model_history['val_loss'])\n",
    "   axs[1].set_title('Model Loss')\n",
    "   axs[1].set_ylabel('Loss')\n",
    "   axs[1].set_xlabel('Epoch')\n",
    "   axs[1].set_xticks(np.arange(1, len(model_history['loss']) + 1), len(model_history['loss']) / 10)\n",
    "   axs[1].legend(['train', 'val'], loc='best')\n",
    "   plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-25025fac5012>:9: MatplotlibDeprecationWarning: Passing the minor parameter of set_ticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n",
      "  axs[0].set_xticks(np.arange(1, len(model_history['accuracy']) + 1), len(model_history['accuracy']) / 10)\n",
      "<ipython-input-23-25025fac5012>:17: MatplotlibDeprecationWarning: Passing the minor parameter of set_ticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n",
      "  axs[1].set_xticks(np.arange(1, len(model_history['loss']) + 1), len(model_history['loss']) / 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABIA0lEQVR4nO3dd5iddZ338fc3k0lPSCWkQBIggAQhSAwgqGAFlKKgBlHQ9ZFFYRdY3QW3POg+squ76tplLaxlKUaUphQBIaEEIWCAEFpIISG992SS+T1/3PeQYZgkk2TO3Ke8X9d1rnPucs75nGHIb77n/pVIKSFJkiRJqnydig4gSZIkSWofFniSJEmSVCUs8CRJkiSpSljgSZIkSVKVsMCTJEmSpCphgSdJkiRJVcICT9pLETEyIlJEdG7DuZ+KiIc6IpckSZXKtlXacxZ4qikRMScitkTEwBb7p+UNyciCojXP0jMi1kXEHUVnkSRpV8q5bd2dQlGqFhZ4qkWzgXObNiLizUD34uK8wTnAZuB9ETGkI9/YBlCStIfKvW2VaoYFnmrRr4Dzm21fAPyy+QkRsU9E/DIilkbE3Ij454jolB+ri4hvRMSyiJgFfKCV5/4sIhZGxKsR8dWIqNuNfBcA1wBPA+e1eO0TI+KRiFgVEfMi4lP5/u4R8c086+qIeCjfd1JEzG/xGnMi4j354y9HxE0R8b8RsQb4VESMj4gp+XssjIjvR0SXZs8fExH3RMSKiFgcEf8YEftFxIaIGNDsvGPyn1/9bnx2SVJlKve29Q0iYmhE3Ja3ZzMj4rPNjo2PiKkRsSZv676V7++Wt5nL83by8YgYvDc5pPZmgada9CjQJyLelDcOHwP+t8U53wP2AQ4E3knWaH06P/ZZ4IPA0cA4situzf0C2AocnJ/zPuD/tCVYRBwAnARcl9/Ob3HszjzbIGAsMC0//A3gGOBtQH/gH4DGtrwncCZwE9A3f89twOXAQOB44N3A5/MMvYF7gbuAoflnvC+ltAh4APhos9f9BHBjSqmhjTkkSZWrbNvWnbgBmE/Wnp0D/FtEvDs/9h3gOymlPsBBwMR8/wX5Z9gfGABcBGzcyxxSu7LAU61q+qbxvcDzwKtNB5o1TF9KKa1NKc0Bvgl8Mj/lo8C3U0rzUkorgH9v9tzBwKnAZSml9SmlJcB/ARPamOt84OmU0gyyhmdMRBydHzsPuDeldENKqSGltDylNC3/9vOvgEtTSq+mlLallB5JKW1u43tOSSndklJqTCltTCk9kVJ6NKW0Nf/s/03WEEPW+C5KKX0zpbQp//n8OT/2C7KirulneC7Zz1mSVBvKtW19g4jYHzgRuCJvz6YBP22WpwE4OCIGppTWpZQebbZ/AHBw3t4+kVJas6c5pFJwvI1q1a+AycAoWnQhIbty1QWY22zfXGBY/ngoMK/FsSYjgHpgYUQ07evU4vydOR/4CUBKaUFETCL7tvAvZN8WvtzKcwYC3XZwrC1ely0iDgG+RfYNag+yfyeeyA/vKAPArcA1EXEgcAiwOqX02B5mkiRVnnJtW1szFFiRUlrb4j3H5Y8/A/wr8HxEzAa+klL6Pdln3B+4MSL6kl2l/Cd7q6iceAVPNSmlNJdsQPhpwO9aHF5G9g3diGb7DmD7N5ELyf5xb36syTyyCVIGppT65rc+KaUxu8oUEW8DRgNfiohFEbEIOBY4N5/8ZB5ZN5GWlgGbdnBsPVmR1vQedWTdO5tLLbZ/RPbN6+i8a8o/Ak0t6o4ykFLaRNaF5Tyyb0C9eidJNaQc29adWAD0z4cevCFPSumllNK5wL7A14GbIqJn3oPmKymlw8mGRXyQ1489lApngada9hngXSml9c13ppS2kRUqV0dE74gYAfwd28cSTAT+NiKGR0Q/4Mpmz10I/BH4ZkT0iYhOEXFQRLyTXbsAuAc4nGx83VjgCLIC7VSy8XHviYiPRkTniBgQEWNTSo3AtcC38gHjdRFxfER0BV4EukXEB/LJTv4Z6LqLHL2BNcC6iDgM+FyzY78H9ouIyyKia/7zObbZ8V8CnwLO4I1jLyRJ1a/c2tYmXfMJUrpFRDeyQu4R4N/zfUfm2a8DiIhPRMSgvI1dlb/Gtog4OSLenH9huoasaN22GzmkkrPAU81KKb2cUpq6g8N/Q3b1axbwEHA9WREFWRfKu4GngCd547eU55N1Q5kBrCSbwGSnyx3kjc1Hge+llBY1u80muxJ2QUrpFbJvRb8ArCCbYOWo/CW+CDwDPJ4f+zrQKaW0mmyClJ+SNWbryQaU78wXgY8Da/PP+uumA3lXlvcCpwOLgJeAk5sdf5hscpcn8/EVkqQaUk5tawvryCZDabq9i2ys+Eiyq3k3A1ellO7Jzz8FeDYi1pFNuDIh76myX/7ea4DngEn4habKTKTUsneWJO25iPgTcH1K6adFZ5EkSao1FniS2k1EvJWsm+n+LQauS5IkqQPYRVNSu4iIX5CtkXeZxZ0kSVIxvIInSZIkSVXCK3iSJEmSVCUs8CRJkiSpSnQuOsDuGjhwYBo5cmTRMSRJHeCJJ55YllIaVHSOSmEbKUm1YWftY8UVeCNHjmTq1B0tryJJqiYRMbfoDJXENlKSasPO2ke7aEqSJElSlbDAkyRJkqQqYYEnSZIkSVWi4sbgSZKktmtoaGD+/Pls2rSp6Cgl1a1bN4YPH059fX3RUSSpUBZ4kiRVsfnz59O7d29GjhxJRBQdpyRSSixfvpz58+czatSoouNIUqHsoilJUhXbtGkTAwYMqNriDiAiGDBgQNVfpZSktrDAkySpylVzcdekFj6jJLVFyQq8iLg2IpZExPQdHI+I+G5EzIyIpyPiLaXKIkmSirFq1Sp++MMf7vbzTjvtNFatWtX+gSSpypXyCt7PgVN2cvxUYHR+uxD4UQmzSJKkAuyowNu2bdtOn3fHHXfQt2/fEqWSpOpVsklWUkqTI2LkTk45E/hlSikBj0ZE34gYklJaWKpMO7N2UwMr1zewfP1mVm7Ywor1DTRsaywiiiRVhTOOGkrPrs7lVeuuvPJKXn75ZcaOHUt9fT29evViyJAhTJs2jRkzZnDWWWcxb948Nm3axKWXXsqFF14IwMiRI5k6dSrr1q3j1FNP5cQTT+SRRx5h2LBh3HrrrXTv3r3gTyap6mxrgI2rYPMa2LYFGrfmt23ZdsNG2Lopu2/YCJ3qoL471PfYfuvae/utS08ooPt4kS3vMGBes+35+b43FHgRcSHZVT4OOOCAdg/y48kv8293PN/urytJteykQwdZ4Imvfe1rTJ8+nWnTpvHAAw/wgQ98gOnTp7822+W1115L//792bhxI29961s5++yzGTBgwOte46WXXuKGG27gJz/5CR/96Ef57W9/yyc+8YkiPo5UPVKCdYu3FzSb18CmNbB5LWxZl9033Rq3ZuenRiDlBc9m2LolK3i2bcmKo6bjKWX3neqzAqhzN+jcNSuAuvfLbj36Q/f+UFcPm1bBptVZlk2robEBohMQ2X2nztBrX+gzNLv1Hgq9B0PXPq0XUClln2H9suwzrl20/X7DsvxzNfuMm1Zl792wvn1/xtEpK/S69c0/d9/s8cgTYfxn2/e9mimy5W2tnE2tnZhS+jHwY4Bx48a1es7emP7qGgb26sIVpxzGgF5d6NejC/17dqFr57r2fitJqhmDenctOkLZiIhuwGSgK1nbe1NK6aqI6A/8GhgJzAE+mlJamT/nS8BngG3A36aU7t7bHF+5/VlmLFizty/zOocP7cNVp49p8/njx49/3VIG3/3ud7n55psBmDdvHi+99NIbCrxRo0YxduxYAI455hjmzJmz17mldrd1Myx8Cub9GZY8nxULDZtg68bsvr479BsJ/UdBv1HQb0RWAG3dlD132+asSAKywia/Tym/mtSQHd/WkF9VasgLrfw5PQdlRVCvfaHX4Oz9GjZCwwbYsiEreJa9CAufhkX5bdPqnX+m+p7QtVeWMzplmaJTdqvrCp27ZMVbXZfs/V4ryiK7b2zIPvuGZdl9w4a8oNzB+0ZdVgR1qicrFBvzz9/Q+nOibnux2K1v9jNcvzx7v62tzKrbqTP0GJAVhl17ZcVXj5HQbZ/sfbv3y16nW5/sM3XqvP1Wlxer9d2hc3eo75bla9iY/Xwb8tvmtXnBvDYvmNdkn3njyqyQXP1q9t+nhIos8OYD+zfbHg4sKCLIyg1bGNavBx8Zt/+uT5YkafdtBt6VUloXEfXAQxFxJ/Bh4L6U0tci4krgSuCKiDgcmACMAYYC90bEISmlnQ9cqwA9e/Z87fEDDzzAvffey5QpU+jRowcnnXRSq0sddO26/cuCuro6Nm7c2CFZVQVSgnVLYNUrsGUtbFmf39ZBY2PWxa75H/HR6fVXhJoKle0vmBcbTVe51mVF0sKnYOG0rBAD6LVfVjzUd9teDGxaDTNuyf7QL1LnbjB4DIz5cHbfo39e8PTJCpsuvbbfdyrRxY5tW7NiZ8OK7GfWdGVrZ10at2yAtQthzYLsfu2i7a+xcWV2694X9h0DPQdmtx4Dsyt9vfaD3vtlVww7Vf8iAkUWeLcBl0TEjcCxwOqixt+t3LCFgb38plmSVBr5ePN1+WZ9fktk49FPyvf/AngAuCLff2NKaTMwOyJmAuOBKXuTY3eutLWX3r17s3bt2laPrV69mn79+tGjRw+ef/55Hn300Q5Op6rQ8g//Na/Cspmw7IXsitWurlLtjegEXXrDvm+CY/8a9j8Who/Piood2bgKVs6BVXOzArRzt+1XwjrV5yc1dXMkK3jq6rNjdV2grnP2uOmqUqe67NwNy7NuiOsWZ0Vtw4bsClx996xwqu8O/Q+CAQdnr1Gkus7bi7C26tIDBhyU3bRTJfuvGxE3kDVaAyNiPnAVWYNGSuka4A7gNGAmsAH4dKmy7MrK9Q0csm/vot5eklQDIqIOeAI4GPhBSunPETG46cvNlNLCiNg3P30Y0LzaaRqnXnEGDBjACSecwBFHHEH37t0ZPHj7H76nnHIK11xzDUceeSSHHnooxx13XIFJVZiVc2HOg7BiVjZmav2yrIvdhuXZ1Z2msV+pMeuS2DTpRdMEGNs2v/E1e+4Lgw6FI86BgYdA/wPzq1I982KnZ1YgvTaJRkN2Val5YfW6x83U1ecTaPTKuyXu5iQa3ftC97EwdOzuPW9XevSHgaPb9zVVkUo5i+a5uziegItL9f67Y9WGLfTt0aXoGJKkKpZ3rxwbEX2BmyPiiJ2c3uZx6qWeiKw9XH/99a3u79q1K3feeWerx5rG2Q0cOJDp07cvqfvFL36x3fOpRNYshFkPwLxHs/FaPQZkRUiP/tnkHHMfgtmTs+6TkI2naupW13MA7Pfm7HnRKetW1zT2q3mXyk51WdfCPkOh95Dt9936FPrRpSLV/PRmm7duY/2WbfTvWb/rkyVJ2ksppVUR8QDZWrGLm5YIioghwJL8tDaPUy/1RGRSm21cBa88CrMnwcv3w9Lnsv1d98nuW06S0TSb4PGXwKh3wMBDa2J8lFRqNV/grdqQzTzkFTxJUqlExCCgIS/uugPvAb5ONh79AuBr+f2t+VNuA66PiG+RTbIyGnisw4NLzaW0fYKSppkCV70Cc6fA3Edg8XQgZVfdRhwPR02Ag06GwW/OCrdtDdlEGBuWZ6816NDSTeIh1bCaL/BWrM9mO+pngSdJKp0hwC/ycXidgIkppd9HxBRgYkR8BngF+AhASunZiJgIzAC2AhdXwwyaqiApZROBvPoEzH8c5k+FRc+0Pt6tc3fYfzyc9CUY8TYYPi4bm9ZSXf32afwllUzNF3grN+QFnl00JUklklJ6Gji6lf3LgXfv4DlXA1eXOJqUaVrD7ZVHs3Xc5v0Z1i/NjtX3gKFHZwsz99o3n2Ckd3bfc1A2Vq6zX5RL5aLmC7ymLppewZMkSTVn6Qvw4Ley9dmaFobuNwoOfk92VW7YONj38OKn1ZfUZjX/f2tTF83+PS3wJElSjVj4NDz4TZhxa9adcux5cOA7Yf/jdr6Gm6SyV/MF3qq8i2bfHnbRlCSpaL169WLdunW7PlF7Zt5jWWH34l3Z8gJv/wIc9/lsWQJJVaHmC7wV6xvo0aWOrp2dxUmSJFWhlODl++DB/8rWnuveD07+52xMXfe+RaeT1M5qvsBbtWGL4+8kSSqRK664ghEjRvD5z38egC9/+ctEBJMnT2blypU0NDTw1a9+lTPPPLPgpFVo6xZ4/nZ4+DvZBCq9h8L7/x2OuQC69Cw6naQSqfkCb+WGLc6gKUlSiUyYMIHLLrvstQJv4sSJ3HXXXVx++eX06dOHZcuWcdxxx3HGGWcQEQWnrRIrZsOTv4C//G82E2b/g+CM78GRH4POXYtOJ6nEar7AW7GhwSt4kqTacOeV2Vpm7Wm/N8OpX9vh4aOPPpolS5awYMECli5dSr9+/RgyZAiXX345kydPplOnTrz66qssXryY/fbbr32z1ZpZk7KrdS//CSLgkFNh3KfhoHe5oLhUQ2q+wFu1YQsj+vcoOoYkSVXrnHPO4aabbmLRokVMmDCB6667jqVLl/LEE09QX1/PyJEj2bRpU9ExK9fCp+DeL2eFXe8hcNKVcPQnYZ9hRSeTVICaL/BWrN/iEgmSpNqwkyttpTRhwgQ++9nPsmzZMiZNmsTEiRPZd999qa+v5/7772fu3LmF5Kp4K+fAn66GZyZmE6e872p46/+B+m5FJ5NUoJou8LZua2Ttpq0ukSBJUgmNGTOGtWvXMmzYMIYMGcJ5553H6aefzrhx4xg7diyHHXZY0RErz1O/htsugaiDE/8OTrjUGTElATVe4K3a2ADgGDxJkkrsmWe2j/0bOHAgU6ZMafU818DbhZSycXb3XgUj3w4f/jH0GVp0KkllpKYLvJXrs0XO+9lFU5IklbvGbXDXl+Cx/4YjzoazfuSsmJLeoLYLvA1NV/DsoilJkspYwyb43Wfhudvg+Evgvf8POnUqOpWkMlTTBd6Kpit4dtGUJEnlauMquOFceOWRbCKVt11SdCJJZaymC7xVG+yiKUmqfimlql9EPKVUdITSWLcEfvVhWPo8nP0zePM5RSeSVOZq+tq+XTQlSdWuW7duLF++vHoLILLibvny5XTrVmXLA6ycA9e+H1a8DB+/0eJOUpvU9BW8lRu20LVzJ7rX1xUdRZKkkhg+fDjz589n6dKlRUcpqW7dujF8+PCiY7SfxTPgVx+CrZvg/Fth//FFJ5JUIWq7wFu/hX49ulR9txVJUu2qr69n1KhRRcfQ7nj1iaxbZudu8Ok7YfDhRSeSVEFqu8DbsMXxd5IkqXysfhWunwDd9oELboN+I4tOJKnC1HiB1+D4O0mSVB4aNsKvz4OGDXDB7RZ3kvZIjU+yssUlEiRJUvFSgtsvhQV/gQ//BPY9rOhEkipUbRd467fQr6dX8CRJUsGmfB+e/jWc/M9w2GlFp5FUwWq2wNvWmFi9scEreJIkqVgz74V7/i8cfia844tFp5FU4Wq2wFuzsYHGhAWeJEkqzso5cNNfwb6Hw5k/BGf2lrSXarbAW7lhC4BdNCVJUjEat8HNF2Xj7z72v9C1V9GJJFWBmp1Fc+WGBgD6egVPkiQVYcr34ZUpcNaPoL9rFUpqH7V7BW99dgWvvwWeJEnqaIumw5++Cod9EI46t+g0kqpISQu8iDglIl6IiJkRcWUrx/tFxM0R8XREPBYRR5QyT3OvddG0wJMkSR1p62a4+a+zxcxP/47j7iS1q5IVeBFRB/wAOBU4HDg3Ig5vcdo/AtNSSkcC5wPfKVWelhyDJ0mSCvHAv8Pi6XDG96DnwKLTSKoypbyCNx6YmVKalVLaAtwInNninMOB+wBSSs8DIyNicAkzvWblhgY6dwp6da3ZYYiSJKmjvfIoPPwdOPqTcOipRaeRVIVKWeANA+Y1256f72vuKeDDABExHhgBDG/5QhFxYURMjYipS5cubZdwqzZsoW+PLoTdIiRJUkfYuhlu+RzsMxze/29Fp5FUpUpZ4LVWOaUW218D+kXENOBvgL8AW9/wpJR+nFIal1IaN2jQoHYJt2L9FvrbPVOSJHWUKT+AFbPgg9+Gbn2KTiOpSpWywJsP7N9seziwoPkJKaU1KaVPp5TGko3BGwTMLmGm16zc0OASCZKkDhER+0fE/RHxXEQ8GxGX5vu/HBGvRsS0/HZas+d8KZ+k7IWIeH9x6dUu1iyEyd+AQ0+Dg99ddBpJVayUA9AeB0ZHxCjgVWAC8PHmJ0REX2BDPkbv/wCTU0prSpjpNSvXb+GgQS4oKknqEFuBL6SUnoyI3sATEXFPfuy/UkrfaH5yPinZBGAMMBS4NyIOSSlt69DUaj/3/Ss0NsD7vlp0EklVrmQFXkppa0RcAtwN1AHXppSejYiL8uPXAG8CfhkR24AZwGdKlaellRsanEFTktQhUkoLgYX547UR8RxvHJfe3JnAjSmlzcDsiJhJNnnZlJKHVfub/wQ8dT2ccBkMOKjoNJKqXEmnkEwp3QHc0WLfNc0eTwFGlzLDDnK9NsmKJEkdKSJGAkcDfwZOAC6JiPOBqWRX+VaSFX+PNntaaxOVqRI0NsKd/wC9BsM7vlh0Gkk1oKQLnZertZu3srUx0d8CT5LUgSKiF/Bb4LJ8SMKPgIOAsWRX+L7ZdGorT285UVnTa7b7TNNqR89MhFenwruvgq69i04jqQbUZIG3an0DAH172EVTktQxIqKerLi7LqX0O4CU0uKU0raUUiPwE7JumNCGicqalGKmabWTzevgnqtg6FvgqHOLTiOpRtRkgbdiwxYA+vf0Cp4kqfQiW3T1Z8BzKaVvNds/pNlpHwKm549vAyZERNd8srLRwGMdlVft5OFvw7pFcOrXoVNN/sklqQAlHYNXrlbmBZ5j8CRJHeQE4JPAM/narwD/CJwbEWPJul/OAf4aIJ+UbCLZBGRbgYudQbPCrFsKU34IYz4E+4/f9fmS1E5qssBblRd4/eyiKUnqACmlh2h9XN0drexres7VwNUlC6XSeuhbsHUjnPxPRSeRVGNqsr/AinwMnl00JUlSu1v9Kjz+Mzjq4zCwwycLl1TjarLAW7VhC50C+nTzCp4kSWpnk/8DUiO88x+KTiKpBtVkgbdifbYGXqdOrfWWkSRJ2kPLX4YnfwXHfAr6jSg6jaQaVJMF3qoNDS6RIEmS2t8DX4O6Li5qLqkwNVngrdywhX7OoClJktrT4hnwzG/g2Auh935Fp5FUo2qywFux3gJPkiS1s/uvhq694YTLik4iqYbVZIG3akODSyRIkqT2s/BpeP73cPzF0KN/0Wkk1bCaK/BSSqzYsMUlEiRJUvt5/CfQuTsce1HRSSTVuJor8DY2bGPL1kb62kVTkiS1h02r4Zmb4M3nQPe+RaeRVONqrsBbuaFpkXO7aEqSpHbw1I3QsAHe+pmik0hSDRZ467cAeAVPkiTtvZTg8Z/B0LfA0KOLTiNJNVjgbcgKPGfRlCRJe23uw7DsBa/eSSobnYsO0NHGjejPPZe/g2H9uhcdRZIkVbrHfwbd9oExHy46iSQBNVjgde9Sx+jBvYuOIUmSKt26JfDc7TD+s9ClR9FpJAmowS6akiRJ7eLJX0JjA4z7q6KTSNJrLPAkSZJ2V+M2eOLnMOodMHB00Wkk6TUWeJIkSbvrpXtg9TwY5+QqksqLBZ4kSdLumvoz6LUfHPaBopNI0utY4EmSJO2OdUth5r1w9HlQV190Gkl6HQs8SZKk3fHcbZAa4Yizi04iSW9ggSdJkrQ7ZtwCA0bDvocXnUSS3sACT5Ikqa3WLYU5D8GYsyCi6DSS9AYWeJIkSW31/O1Z98zDzyo6iSS1ygJPkiSprZ69BQYcDIPHFJ1EklplgSdJktQW65fBnAezq3d2z5RUpizwJEmS2uK5vHvmmLOKTiJJO1TSAi8iTomIFyJiZkRc2crxfSLi9oh4KiKejYhPlzKPJEnSHptxC/Q/CAYfUXQSSdqhkhV4EVEH/AA4FTgcODciWs4nfDEwI6V0FHAS8M2I6FKqTJIkSXtk/TKY/aCzZ0oqe6W8gjcemJlSmpVS2gLcCJzZ4pwE9I6IAHoBK4CtJcwkSZK0+567HdI2Z8+UVPZKWeANA+Y1256f72vu+8CbgAXAM8ClKaXGli8UERdGxNSImLp06dJS5ZUkSWrdjFug/4Gw35uLTiJJO1XKAq+1/gupxfb7gWnAUGAs8P2I6POGJ6X045TSuJTSuEGDBrV3TkmSpB1bvzzrnunsmZIqQCkLvPnA/s22h5NdqWvu08DvUmYmMBs4rISZJEnqcBGxf0TcHxHP5ZOKXZrv7x8R90TES/l9v2bP+VI+SdkLEfH+4tIrW9x8m7NnSqoIpSzwHgdGR8SofOKUCcBtLc55BXg3QEQMBg4FZpUwkyRJRdgKfCGl9CbgOODifOKxK4H7UkqjgfvybfJjE4AxwCnAD/PJy1SE5/8A/UbCfkcWnUSSdqlkBV5KaStwCXA38BwwMaX0bERcFBEX5af9P+BtEfEMWcN2RUppWakySZJUhJTSwpTSk/njtWTt4jCyycd+kZ/2C+Cs/PGZwI0ppc0ppdnATLLJy9TRtqyHWZPg0NPsnimpInQu5YunlO4A7mix75pmjxcA7ytlBkmSyklEjASOBv4MDE4pLYSsCIyIffPThgGPNntaaxOVqSPMmgTbNsMh9pKVVBlKutC5JEnaLiJ6Ab8FLksprdnZqa3sazlRWdNrOtN0Kb14F3TpDQe8regkktQmFniSJHWAiKgnK+6uSyn9Lt+9OCKG5MeHAEvy/W2ZqAxwpumSSglevBsOfhd07lJ0GklqEws8SZJKLCIC+BnwXErpW80O3QZckD++ALi12f4JEdE1IkYBo4HHOiqvcgufgnWL4JBTi04iSW1W0jF4kiQJgBOATwLPRMS0fN8/Al8DJkbEZ8hmlv4IQD4p2URgBtkMnBenlLZ1eOpa9+JdQMDo9xadRJLazAJPkqQSSyk9ROvj6iBfLqiV51wNXF2yUNq1F++C4W+FngOLTiJJbWYXTUmSpJbWLoIFf3H2TEkVxwJPkiSppZf+mN0fckqxOSRpN1ngSZIktfTi3bDP/jB4TNFJJGm3WOBJkiQ117AJXv5T1j0zdjR0UpLKkwWeJElSc3MegoYNds+UVJEs8CRJkpp78S6o7wEj3150EknabRZ4kiRJTVLKxt8deBLUdys6jSTtNgs8SZKkJkueg9Wv2D1TUsWywJMkSWrStDzC6PcWm0OS9pAFniRJUpOZ98K+Y6DP0KKTSNIescCTJEkC2LwWXnkURr+n6CSStMcs8CRJkgBmPwiNDXCwBZ6kyrXLAi8iPhgRFoKSJKm6zbwX6nvC/scVnUSS9lhbCrcJwEsR8R8R8aZSB5IkSepwKcHMe+DAd0LnLkWnkaQ9tssCL6X0CeBo4GXgfyJiSkRcGBG9S55OkiSpIyx/GVa9Age/u+gkkrRX2tT1MqW0BvgtcCMwBPgQ8GRE/E0Js0mSJHWMmfdm9wdZ4EmqbG0Zg3d6RNwM/AmoB8anlE4FjgK+WOJ8kiRJpTfzXhhwMPQfVXQSSdorndtwzkeA/0opTW6+M6W0ISL+qjSxJEmSOkjDRpjzEBxzQdFJJGmvtaXAuwpY2LQREd2BwSmlOSml+0qWTJIkqSPMfQS2bnR5BElVoS1j8H4DNDbb3pbvkyRJqnwz74O6rjDihKKTSNJea0uB1zmltKVpI3/s/MGSJKk6zLwHRp4AXXoUnUSS9lpbCrylEXFG00ZEnAksK10kSZKkDrJyLix70e6ZkqpGW8bgXQRcFxHfBwKYB5xf0lSSJEkd4eV8OgELPElVYpcFXkrpZeC4iOgFREppbeljSZIkdYCZ98E++8PAQ4pOIkntoi1X8IiIDwBjgG4RAUBK6V9LmEuSpLIVET2BjSmlxog4BDgMuDOl1FBwNO2ObQ0waxIc8WHI/76RpErXloXOrwE+BvwNWRfNjwAjSpxLkqRyNpnsS89hwH3Ap4GfF5pIu2/BX2DLWjjo5KKTSFK7acskK29LKZ0PrEwpfQU4Hti/LS8eEadExAsRMTMirmzl+N9HxLT8Nj0itkVE/937CJIkdbhIKW0APgx8L6X0IeDwgjNpd82alN2PfEexOSSpHbWlwNuU32+IiKFAAzBqV0+KiDrgB8CpZI3euRHxusYvpfSfKaWxKaWxwJeASSmlFbuRX5KkIkREHA+cB/wh39emYQ8qI7MnwX5vhp4Dik4iSe2mLQXe7RHRF/hP4ElgDnBDG543HpiZUpqVr513I3DmTs4/t42vK0lS0S4j+2Ly5pTSsxFxIHB/sZG0W7ZsgHl/hlHvLDqJJLWrnX7bGBGdgPtSSquA30bE74FuKaXVbXjtYWRLKjSZDxy7g/fpAZwCXLKD4xcCFwIccMABbXhrSZJKJ6U0CZgEr7WVy1JKf1tsKu2WeY/Cti1w4ElFJ5GkdrXTK3gppUbgm822N7exuINsQpY3vOQOzj0deHhH3TNTSj9OKY1LKY0bNGhQG99ekqTSiIjrI6JPPpvmDOCFiPj7onNpN8yaBJ06wwHHF51EktpVW7po/jEizo7Y7fmD5/P6yViGAwt2cO4E7J4pSaoch6eU1gBnAXcABwCfLDSRds/sSTD8rdC1V9FJJKldtaXA+zvgN8DmiFgTEWsjYk0bnvc4MDoiRkVEF7Ii7raWJ0XEPsA7gVt3I7ckSUWqj4h6sgLv1nz9ux31UgEgIq6NiCURMb3Zvi9HxKvNZpQ+rdmxL+WzUL8QEe8v1QepSRtXwoJpjr+TVJV2OeNXSqn3nrxwSmlrRFwC3A3UAdfmA9Evyo9fk5/6IeCPKaX1e/I+kiQV4L/JJh17CpgcESOAXX35+XPg+8AvW+z/r5TSN5rvyGedngCMAYYC90bEISmlbXsfXcx5GEgwyuURJFWfXRZ4EdHqv34ppcm7em5K6Q6yrivN913TYvvnuDisJKmCpJS+C3y32a65EbHT1bJTSpMjYmQb3+JM4MaU0mZgdkTMJJudesqe5FULsydBfY+si6YkVZm2rNnTfNB4N7IG5gngXSVJJElSmcuHF1wFNH0JOgn4V6CtE5E1d0lEnA9MBb6QUlpJNhP1o83OmZ/vay2LM03vrlmTsslVOncpOokktbtdjsFLKZ3e7PZe4AhgcemjSZJUtq4F1gIfzW9rgP/Zg9f5EXAQMBZYyPaZq9s8E7UzTe+mNQth2QtwoOPvJFWntlzBa2k+WZEnSVKtOiildHaz7a9ExLTdfZGU0mtfmEbET4Df55u7MxO1dsfsfISJE6xIqlJtGYP3PbZ/a9iJ7FvGp0qYSZKkcrcxIk5MKT0EEBEnABt390UiYkhKaWG++SGgaYbN24DrI+JbZJOsjAYe2/vYYvYk6N4P9juy6CSSVBJtuYI3tdnjrcANKaWHS5RHkqRKcBHwy3wsHsBK4IKdPSEibgBOAgZGxHyyMXwnRcRYsi9S5wB/DZDPOj2RbBH1rcDFzqDZDlLKxt+NfDt0astKUZJUedpS4N0EbGpqWCKiLiJ6pJQ2lDaaJEnlKaX0FHBURPTJt9dExGXA0zt5zrmt7P7ZTs6/Grh6L6OquRWzYM18ePvlRSeRpJJpy9dX9wHdm213B+4tTRxJkipHSmlNSqlp/bu/KzSMdm32pOx+1ElFppCkkmpLgdctpbSuaSN/3KN0kSRJqkitzXypcjJ7MvQeCgMOKjqJJJVMWwq89RHxlqaNiDiGPRhILklSlWt1GQOViZRgzkMw6u0Q1uKSqldbxuBdBvwmIpqmZx4CfKxkiSRJKlMRsZbWC7ng9cMZVG6WvQjrl8LIE4tOIkkltcsCL6X0eEQcBhxK1oA9n1JqKHkySZLKTEqpd9EZtIfmPJjdW+BJqnK77KIZERcDPVNK01NKzwC9IuLzpY8mSZLUTuY8DH2GQb9RRSeRpJJqyxi8z6aUVjVtpJRWAp8tWSJJkqT21DT+bsQJjr+TVPXaUuB1itj+r2FE1AFdShdJkiSpHS17CdYvsXumpJrQlklW7gYmRsQ1ZAPLLwLuLGkqSZKk9uL4O0k1pC0F3hXAhcDnyCZZ+QvZTJqSJEnlb85D2fp3/Q8sOokkldwuu2imlBqBR4FZwDjg3cBzJc4lSZK091KCuQ/DSMffSaoNO7yCFxGHABOAc4HlwK8BUkond0w0SZKkvbR8JqxbbPdMSTVjZ100nwceBE5PKc0EiIjLOySVJElSe3ht/N3bi80hSR1kZ100zwYWAfdHxE8i4t1kY/AkSZIqw5yHoPcQx99Jqhk7LPBSSjenlD4GHAY8AFwODI6IH0XE+zoonyRJ0p5x/TtJNagtk6ysTyldl1L6IDAcmAZcWepgkiRJe2X5y46/k1Rz2rLQ+WtSSitSSv+dUnpXqQJJkiS1C8ffSapBu1XgSZIkVYw5D0Gv/WDAQUUnkaQOY4EnSZKqT9P4u5EnOv5OUk2xwJMkSdVnxSxYtyhb4FySaogFniRJqj5zHsruRzjBiqTaYoEnSZKqz9xHoOcgGDi66CSS1KEs8CRJUvWZ+wgccLzj7yTVHAs8SZJUXVbNg9WvZAucS1KNscCTJEnV5ZUp2f2ItxWbQ5IKUNICLyJOiYgXImJmRFy5g3NOiohpEfFsREwqZR5JklQD5j4MXfeBwWOKTiJJHa5zqV44IuqAHwDvBeYDj0fEbSmlGc3O6Qv8EDglpfRKROxbqjySJKlGzH0EDjgWOtUVnUSSOlwpr+CNB2amlGallLYANwJntjjn48DvUkqvAKSUlpQwjyRJqnbrlsKyF+2eKalmlbLAGwbMa7Y9P9/X3CFAv4h4ICKeiIjzW3uhiLgwIqZGxNSlS5eWKK4kSap4r42/c4IVSbWplAVea/MSpxbbnYFjgA8A7wf+JSIOecOTUvpxSmlcSmncoEGD2j+pJEmqDnMfgc7dYcjYopNIUiFKNgaP7Ird/s22hwMLWjlnWUppPbA+IiYDRwEvljCXJEmqVq88AsPHQecuRSeRpEKU8gre48DoiBgVEV2ACcBtLc65FXh7RHSOiB7AscBzJcwkSVIhIuLaiFgSEdOb7esfEfdExEv5fb9mx76Uz0L9QkS8v5jUFWbTalj0jN0zJdW0khV4KaWtwCXA3WRF28SU0rMRcVFEXJSf8xxwF/A08Bjw05TS9B29piRJFeznwCkt9l0J3JdSGg3cl28TEYeTfTE6Jn/OD/PZqbUz8x6D1OgEK5JqWim7aJJSugO4o8W+a1ps/yfwn6XMIUlS0VJKkyNiZIvdZwIn5Y9/ATwAXJHvvzGltBmYHREzyWanntIhYSvV3IehU2cY/taik0hSYUq60LkkSdqpwSmlhQD5fdN6sG2ZiVotzZ0CQ4+GLj2KTiJJhbHAkySp/LRlJursRJcSyjRshFefsHumpJpngSdJUnEWR8QQgPx+Sb6/LTNRAy4l9Jr5U6GxwQlWJNU8CzxJkopzG3BB/vgCstmlm/ZPiIiuETEKGE02GZl2ZO4jQMD+xxadRJIKVdJJViRJUiYibiCbUGVgRMwHrgK+BkyMiM8ArwAfAchnnZ4IzAC2AhenlLYVErxSvPIIDD4CuvctOokkFcoCT5KkDpBSOncHh969g/OvBq4uXaIqsnVLtkTC0Z8oOokkFc4umpIkqbLNfwwaNsCodxadRJIKZ4EnSZIq26wHIOpg1NuLTiJJhbOLpirf1i2w4C/QuLXoJJKaGz4OOnctOoVqwcv3w7BjoNs+RSeRpMJZ4KmyLXwabvkcLJ5edBJJLV0+A/ZxbW6V2MaVsOBJeMffF51EksqCBZ4q09Yt8OA34cFvQI8BcNY10Gdo0akkNddjQNEJVAtmPwipEQ48uegkklQWLPDU/lKCtYugVDN6r1kAf/g7WPQMvPmjcOrXoUf/0ryXJKm8zXoAuvTKugRLkizw1M5WvQK3XgKzJ5X2fXruCxOuh8M+UNr3kSSVt1n3w8gToa6+6CSSVBYs8NQ+UoIn/gf++C/Z9rv+GXoNLs17deoMh5ziVTtJqnUr58KKWTD+r4tOIkllwwJPe2/VPLjtb7JvUUe9E874HvQbUXQqSVK1m3V/dn+Q4+8kqYkFnvZcSvDkL+Huf8oGuH/gmzDuMxBRdDJJUi14+X7oPRQGHlJ0EkkqGxZ42jOr58Ntfwsv3wcj3w5nfh/6jSw6lSSpVjQ2ZuO9DznVLxYlqRkLPO2elOAvv8qu2jVuhdO+kV2169Sp6GSSpFqy6KlsDTy7Z0rS61jgqXXbGuDBb8HTv866X762fwuseRVGnJhdtes/qriMkqTa9XI+/u7AkwqNIUnlxgJPb7ToGbjlc9n9gSdDz0GvPz7ieHjLp7xqJ0kqzqz7YfAR0GvfopNIUlmxwNN2TVftJv8HdO8PH7sO3vTBolNJkvR6WzbAK4/C+AuLTiJJZccCT5kNK+BXH4KF0+CIc+C0/3SdOUlSeXplSjZk4EDH30lSSxZ4yiZOueXzsPhZ+MgvYMxZRSeSJGnHZt0PdV1gxNuKTiJJZccCTzDlB/DinXDK1y3uJEnl76V74IDjoUuPopNIUtlxloxaN38q3HsVHPZBOPavi04jSdLOrZgNS5+HQ08tOokklSULvFq2cSX85tPQZ2i25IELxUqSyt1Lf8zuD3l/sTkkqUzZRbNWpQS3XAxrF8Jf3Q3d+xWdSJKkXXvxLhh4CPQ/sOgkklSWvIJXi1KCh78NL/wB3vsVGH5M0YkkSdq1zWthzkNevZOknfAKXq1ZtwR+fzk8//ts3N1xny86kSRJbTPrgWx5hENOKTqJJJUtC7xakRI8+zv4wxdhy3p4z1fg+EscdydJqhwv3gXd9oH9jy06iSSVLQu8WrBuKfzh7+C522DYMXDmD2Hfw4pOJUlS2zU2wot/hIPfA3X1RaeRpLJV0jF4EXFKRLwQETMj4spWjp8UEasjYlp++7+lzFOTnr0Zfnhs9q3nu6+Cv/qjxZ0kqfIs/AusX2L3TEnahZJdwYuIOuAHwHuB+cDjEXFbSmlGi1MfTCl9sFQ5atb6ZfCHL8CMW2Do0XDWj2DfNxWdSpKkPfPi3RCdsit4kqQdKmUXzfHAzJTSLICIuBE4E2hZ4Km9zbgtm0hl02p417/ACZdBnb1xJUkV7MW7srF3PfoXnUSSylopu2gOA+Y1256f72vp+Ih4KiLujIgxJcxTG159EiZ+EvYZBn89Cd7xRYs7SVJlW7MAFj7l8giS1Aal/Mu/tekZU4vtJ4ERKaV1EXEacAsw+g0vFHEhcCHAAQcc0M4xq8xf/hc6d4MLbs9mGpMkqdK99Mfs3vF3krRLpbyCNx/Yv9n2cGBB8xNSSmtSSuvyx3cA9RExsOULpZR+nFIal1IaN2jQoBJGrnANm2D6b+FNp1vcSZKqx4t3Q98DYJCThEnSrpSywHscGB0RoyKiCzABuK35CRGxX0S2EFtEjM/zLC9hpur24p2waRWM/XjRSSRJuyEi5kTEM/mM0lPzff0j4p6IeCm/71d0zkI0bMwWOD/kFNdulaQ2KFmBl1LaClwC3A08B0xMKT0bERdFxEX5aecA0yPiKeC7wISUUstunGqraddD76Ew6p1FJ5Ek7b6TU0pjU0rj8u0rgftSSqOB+/Lt2jNrEjRsgNGOv5Oktijp7Bt5t8s7Wuy7ptnj7wPfL2WGmrF2Ecy8D064FDrVFZ1GkrT3zgROyh//AngAuKKoMIV55jfQvR+MekfRSSSpIpR0oXN1oKcnQtpm90xJqkwJ+GNEPJFPLAYwOKW0ECC/37ewdEXZvBae/wOM+TB07lJ0GkmqCM6fXw1SyrpnDn8rDHzDJKSSpPJ3QkppQUTsC9wTEc+39YlVPdP0c7fD1o1w5MeKTiJJFcMreNVg4TRY+pxX7ySpQqWUFuT3S4CbgfHA4ogYApDfL9nBc6t3pumnboR+I2H/8UUnkaSKYYFXDaZdD3Vdsy4skqSKEhE9I6J302PgfcB0spmnL8hPuwC4tZiEBVmzAGZPzq7eOXumJLWZXTQr3dbN2QD0wz4A3fsWnUaStPsGAzfnqwZ1Bq5PKd0VEY8DEyPiM8ArwEcKzNjxnrkJSHbPlKTdZIFX6V68GzauhLHnFZ1EkrQHUkqzgKNa2b8ceHfHJyoTT/8aho2DAQcVnUSSKooFXiWZ8xA8/J1sUpUmS1+AXvvBQScXl0uSpPa0aDosng6nfaPoJJJUcSzwKkVjI/zhi7BuEfQbtX1/z4Ew7tOufSdJqh5P/xo6dXZsuSTtAQu8SvHcrdlMmedcC0ecXXQaSZJKo3FbNv7u4PdCzwFFp5GkiuMsmpWgsREe+DoMPBQOP6voNJIklc6cB2HtAjjyo0UnkaSKZIFXCZqu3r3zH+yKKUmqbk9PhK594NBTi04iSRXJAq/cNTbCpP+AgYfAmA8VnUaSpNLZtBpm3ApvOgPquxedRpIqkgVeuXvuNlgyA955hVfvJEnVber/wJZ1MP6zRSeRpIplgVfOvHonSaoVDZvg0R/CgSfD0LFFp5GkimWBV86evx2WPAvv+Huv3kmSqttTN8C6xXDi5UUnkaSKZoFXrhq3ZVfvBhzssgiSpOrWuA0e+S4MPRpGvaPoNJJU0VwHrxwtfxlu+Twsng5n/8yrd1KNamhoYP78+WzatKnoKCXXrVs3hg8fTn19fdFRVITnboMVs+Cjv4SIotNIUkWzwCsnjY3w2H/DvV+Bzl3grGu8eifVsPnz59O7d29GjhxJVPEfvSklli9fzvz58xk1alTRcdTRUoKH/ivrsXLYB4tOI0kVzwKvXKyYBbdcDK88AqPfD6d/B/oMKTqVpAJt2rSp6os7gIhgwIABLF26tOgoKsKsB2DhU3D6d+2xIkntwAKvaI2N8PhP4N4vQ6d6OOtHcNS5dlGRBFD1xV2TWvmcasVD/wW99oOjJhSdRJKqgpOsFGnFLPjF6XDnP8CIE+DzU2Dsxy3uJJWFVatW8cMf/nC3n3faaaexatWq9g+k6vPqEzB7Ehz/eejcteg0klQVLPCK0NgIf/5v+NEJsOhpOPMHcN5vYJ9hRSeTpNfsqMDbtm3bTp93xx130Ldv3xKlUtVICe7/d+i6Dxzz6aLTSFLVsItmR1sxG277G5jzIBz8nmzMgYWdpDJ05ZVX8vLLLzN27Fjq6+vp1asXQ4YMYdq0acyYMYOzzjqLefPmsWnTJi699FIuvPBCAEaOHMnUqVNZt24dp556KieeeCKPPPIIw4YN49Zbb6V79+4FfzKVhem/hZn3wPuuhm59ik4jSVXDAq+jNDbC1J/BPVdlg8jP+B4c/Um7Y0pqk6/c/iwzFqxp19c8fGgfrjp9zA6Pf+1rX2P69OlMmzaNBx54gA984ANMnz79tZkur732Wvr378/GjRt561vfytlnn82AAQNe9xovvfQSN9xwAz/5yU/46Ec/ym9/+1s+8YlPtOvnUAXasALuvAKGvgWO+1zRaSSpqljgdYSVc+G2S2D2ZDjoXVlxt8/wolNJ0m4ZP37865Yx+O53v8vNN98MwLx583jppZfeUOCNGjWKsWPHAnDMMccwZ86cjoqrcnb3P8GmVXDGLc6cKUntzAKv1Bb8BX7+QSCypQ/ecoFX7STttp1daesoPXv2fO3xAw88wL333suUKVPo0aMHJ510UqsLsnftun3ijLq6OjZu3NghWVXGXv4TPHU9vP0LsN+bi04jSVXHAq+UNq2G33wKuu0Dn74T+o0oOpEktVnv3r1Zu3Ztq8dWr15Nv3796NGjB88//zyPPvpoB6dTRdqyAW6/LFvU/B3/UHQaSapKFnilklI2mcqqeRZ3kirSgAEDOOGEEzjiiCPo3r07gwcPfu3YKaecwjXXXMORRx7JoYceynHHHVdgUlWMB/4NVs2FT/0B6rsVnUaSqpIF3t547nZ45iZ4z1XQ/8DXH3v8pzDjVnjPV+CAY4vJJ0l76frrr291f9euXbnzzjtbPdY0zm7gwIFMnz79tf1f/OIX2z2fKsjcKTDlB3DMp2DkiUWnkaSq5Tp4eyoluP/fYMYt2Xp2f/5xNlMmwMKn4O5/hIPfC2/720JjSpJUuEXPwPUfg36jsi8+JUklY4G3pxZOgyUzsjEEI94Gd/49/PKMrBGbeAH0GAgf+m/o5I9YklTDlr8Mv/oQdO0F598K3fsWnUiSqlpJq4+IOCUiXoiImRFx5U7Oe2tEbIuIc0qZp11NuwHqusLxF8N5N2VLHyx8Cq45EVa9AudcCz0H7Pp1JEmqVqvnwy/PhNQIn7wF+u5fdCJJqnolG4MXEXXAD4D3AvOBxyPitpTSjFbO+zpwd6mytLutW+CZ38BhH9j+TeRbzs/WuPvjv8Cot8OI4wuNKElSodYvg1+elc0ofcHtMOiQohNJUk0o5SQr44GZKaVZABFxI3AmMKPFeX8D/BZ4awmztK+X7oaNK2Dsea/fv89w+Mj/FJNJkqRysfQFuOkzsHoefPJmGDq26ESSVDNK2UVzGDCv2fb8fN9rImIY8CHgmhLmaH/Trode+8FBJxedRJKk8rF1Czzw9Wy4wup5MOG6bJy6JKnDlPIKXrSyL7XY/jZwRUppW0Rrp+cvFHEhcCHAAQcc0F759sy6pfDSH7Oxd53qis0iSWWmV69erFu3rugYKsK8x+C2v4Wlz8ER58ApX4Neg4pOJUk1p5QF3nyg+Wjq4cCCFueMA27Mi7uBwGkRsTWldEvzk1JKPwZ+DDBu3LiWRWLHeuY30LgVjvp4oTEkSSpcYyPMfRie/GXWPvYZBh+fCIe8v+hkklSzSlngPQ6MjohRwKvABOB1VVFKaVTT44j4OfD7lsVd2Zl2PQx9C+x7WNFJJKnkrrjiCkaMGMHnP/95AL785S8TEUyePJmVK1fS0NDAV7/6Vc4888yCk6pDrZoHT90A066DlXOga5+sZ8tJV0LX3kWnk6SaVrICL6W0NSIuIZsdsw64NqX0bERclB+vrHF3AAufhsXPwGnfKDqJpFpz55XZOpvtab83w6lf2+kpEyZM4LLLLnutwJs4cSJ33XUXl19+OX369GHZsmUcd9xxnHHGGeysq732TEScAnyHrB39aUpp5//BSmXVPHjlUXhlSna/ZAaQYNQ74OR/gsM+CF16FBJNkvR6pbyCR0rpDuCOFvtaLexSSp8qZZZ28dQNUNcFjji76CSS1CGOPvpolixZwoIFC1i6dCn9+vVjyJAhXH755UyePJlOnTrx6quvsnjxYvbbb7+i41aVti431K4WTYelz8PK2bBiTna//GVYtyg73qU37D8e3nx21hb2G1myKJKkPVPSAq8srV+WDQTfbQmengiHngo9+rd7LEnaqV1caSulc845h5tuuolFixYxYcIErrvuOpYuXcoTTzxBfX09I0eOZNOmTYXlq2JtXW6o3bx43eUcsjZrI9d2HsD6nvvT0G886w56MysGjmNdv0PJ6k6IhQELF5cqiiRVrcF9unLk8L4le/3aK/AWPws3nrvnzz/6/PbLIkkVYMKECXz2s59l2bJlTJo0iYkTJ7LvvvtSX1/P/fffz9y5c4uOWK1aW27o2JYntedM01NHX861r67hmfV9mbMG1q/bBq/VcBuBaXv1+pIk+OCRQ/j+x99SstevvQJv2Fvgwkl79tz67jDo0PbNI0llbsyYMaxdu5Zhw4YxZMgQzjvvPE4//XTGjRvH2LFjOewwJ50qkbYsN9SuM01//IzTXjcb2tpNDSxes4ktWxOJRCp2HmtJqgr7dK8v6evXXoHXtTcMHVt0CkmqKM88s32Cl4EDBzJlypRWz3MNvHbVluWGSqp3t3p6dyvtHyKSpPbVqegAkiSpVa8tNxQRXciWG7qt4EySpDJXe1fwJEmqADtabqjgWJKkMmeBJ0lSmWptuSFJknbGLpqSVMZSjcxqUSufU5KkUrPAk6Qy1a1bN5YvX171xU9KieXLl9OtW7eio0iSVPHsoilJZWr48OHMnz+fpUuXFh2l5Lp168bw4cOLjiFJUsWzwJOkMlVfX8+oUaOKjiFJkiqIXTQlSZIkqUpY4EmSJElSlbDAkyRJkqQqEZU2O1tELAXm7ubTBgLLmm3vA6xucc6e7iv189ore0c/r2Xucs3Zlp95ueaspt+XSs7u73rbn7cnRqSUBrXD69SEPWgj/f0t5nnVlL1cc/pvdXl8vqJ/Xyop++7acfuYUqr6GzC1xfaPWzlnj/Z1wPPaJXsBz5vawe/Xns/bZfYyyVk1vy+VnN3f9bY/z1v53fz9Lex5VZO9jHP6b3V5fL5Cf18qKXt73mq1i+bt7biv1M/bk9fem/drr+e1phxztiV3qd/P35fWVXv2cvh8reno91P58fe34/+tLiKD7Ux55vT3Ze/er5Kzt5uK66K5JyJiakppXNE59kSlZq/U3GD2olRq9krNDZWdXe2jkn8HzF6MSs1eqbnB7EWp5Oy1cgXvx0UH2AuVmr1Sc4PZi1Kp2Ss1N1R2drWPSv4dMHsxKjV7peYGsxelYrPXxBU8SZIkSaoFtXIFT5IkSZKqXlUXeBFxSkS8EBEzI+LKovPsTERcGxFLImJ6s339I+KeiHgpv+9XZMYdiYj9I+L+iHguIp6NiEvz/WWdPyK6RcRjEfFUnvsr+f6yzt1cRNRFxF8i4vf5dkVkj4g5EfFMREyLiKn5vkrJ3jciboqI5/Pf+ePLPXtEHJr/rJtuayLisnLPrdKyjSy9Sm0fofLbSNvHjleJ7SNUZxtZtQVeRNQBPwBOBQ4Hzo2Iw4tNtVM/B05pse9K4L6U0mjgvny7HG0FvpBSehNwHHBx/rMu9/ybgXellI4CxgKnRMRxlH/u5i4Fnmu2XUnZT04pjW02gLlSsn8HuCuldBhwFNnPv6yzp5ReyH/WY4FjgA3AzZR5bpWObWSHqdT2ESq/jbR97HgV1z5ClbaRpVyDocgbcDxwd7PtLwFfKjrXLjKPBKY3234BGJI/HgK8UHTGNn6OW4H3VlJ+oAfwJHBspeQGhpP9g/Mu4PeV9DsDzAEGtthX9tmBPsBs8vHLlZS9Wdb3AQ9XWm5v7f57YBtZzGeouPYxz1hRbaTtYyG5K759zDNWRRtZtVfwgGHAvGbb8/N9lWRwSmkhQH6/b8F5dikiRgJHA3+mAvLnXTimAUuAe1JKFZE7923gH4DGZvsqJXsC/hgRT0TEhfm+Ssh+ILAU+J+8689PI6InlZG9yQTghvxxJeVW+7KN7GCV1j5CRbeR38b2saNVQ/sIVdJGVnOBF63sc8rQEoqIXsBvgctSSmuKztMWKaVtKbskPxwYHxFHFBypTSLig8CSlNITRWfZQyeklN5C1j3s4oh4R9GB2qgz8BbgRymlo4H1VFCXjYjoApwB/KboLCqcbWQHqsT2ESqzjbR9LExFt49QXW1kNRd484H9m20PBxYUlGVPLY6IIQD5/ZKC8+xQRNSTNV7XpZR+l++umPwppVXAA2RjPCoh9wnAGRExB7gReFdE/C+VkZ2U0oL8fglZP/fxVEb2+cD8/FtsgJvIGrRKyA7ZHwxPppQW59uVklvtzzayg1R6+wgV10baPhaj0ttHqKI2spoLvMeB0RExKq/IJwC3FZxpd90GXJA/voCs737ZiYgAfgY8l1L6VrNDZZ0/IgZFRN/8cXfgPcDzlHlugJTSl1JKw1NKI8l+t/+UUvoEFZA9InpGRO+mx2T93adTAdlTSouAeRFxaL7r3cAMKiB77ly2dz2Bysmt9mcb2QEqtX2Eym0jbR+LUQXtI1RRG1nVC51HxGlk/bDrgGtTSlcXm2jHIuIG4CRgILAYuAq4BZgIHAC8AnwkpbSioIg7FBEnAg8Cz7C9v/s/ko0zKNv8EXEk8Auy349OwMSU0r9GxADKOHdLEXES8MWU0gcrIXtEHEj2rSRkXTquTyldXQnZASJiLPBToAswC/g0+e8PZZw9InqQjbk6MKW0Ot9XET9zlYZtZOlVavsI1dFG2j52rEptH6H62siqLvAkSZIkqZZUcxdNSZIkSaopFniSJEmSVCUs8CRJkiSpSljgSZIkSVKVsMCTJEmSpCphgSd1oIjYFhHTmt2ubMfXHhkR09vr9SRJ6ki2kVL76Fx0AKnGbEwpjS06hCRJZcg2UmoHXsGTykBEzImIr0fEY/nt4Hz/iIi4LyKezu8PyPcPjoibI+Kp/Pa2/KXqIuInEfFsRPwxIroX9qEkSWoHtpHS7rHAkzpW9xbdTz7W7NialNJ44PvAt/N93wd+mVI6ErgO+G6+/7vApJTSUcBbgGfz/aOBH6SUxgCrgLNL+mkkSWo/tpFSO4iUUtEZpJoREetSSr1a2T8HeFdKaVZE1AOLUkoDImIZMCSl1JDvX5hSGhgRS4HhKaXNzV5jJHBPSml0vn0FUJ9S+moHfDRJkvaKbaTUPryCJ5WPtIPHOzqnNZubPd6G42wlSdXBNlJqIws8qXx8rNn9lPzxI8CE/PF5wEP54/uAzwFERF1E9OmokJIkFcA2Umojv7mQOlb3iJjWbPuulFLTNNBdI+LPZF+8nJvv+1vg2oj4e2Ap8Ol8/6XAjyPiM2TfQn4OWFjq8JIklZBtpNQOHIMnlYF8fMG4lNKyorNIklRObCOl3WMXTUmSJEmqEl7BkyRJkqQq4RU8SZIkSaoSFniSJEmSVCUs8CRJkiSpSljgSZIkSVKVsMCTJEmSpCphgSdJkiRJVeL/AxnMGnr1mZ/sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join('models', 'xRGM3.2-Net-HistDict'), 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "    \n",
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
